\chapter{Background \& Related Work}

In this section, constraint optimization and the distributed, as well as dynamic variants are briefly explained and brought into context of the related work. Also, the meeting scheduling problem is described and different algorithm designs and their advantages and disadvantages are explained and related work is mentioned.
    
\section{Dynamic Distributed Constraint Optimization}

% -----------------Constraint Optimization --------------------
    
A constraint optimization problem contains of a set of variables \(V=\{V_{1},V_{2}, ...,  V_{n}\}\). These variables are assigned to a value or state \(s_{j} \in S_{j}\), which is contained in a set of possible values defined by a finite problem domain \(D=\{D_{1},D_{2}, ...,  D_{n}\}\). A constraint \(C = <V_{c}, R_{c}>\) contains one (unary), two (binary) or multiple (k-ary) variables and their relationship. The constraint defines a rule for the variables that needs to be fulfilled. One of those rules could be that none of the variables should take the same value. This would for example be the case for a meeting scheduling problem where none of the meetings should take place at the same time. \newline
A utility function \(u_{{c}_{k}}(S_{{c}_{k}})\) needs to be formulated that defines a certain cost respectively reward for a given configuration of the involved states. The global utility function \(u_{g}\) would then be the summation of all utility functions of all constraints. 

\[u_{g}(s) = u_{c_{1}}(s_{c_{1}}) \oplus \cdots \oplus u_{c_{k}}(s_{c_{k}}) \oplus \cdots \oplus u_{c_{l}}(s_{c_{l}}) \] 

Constraints can be attributed with varying levels of importance through weighting. One can, instead of so-called soft constraints, define hard constraints by multiplying their utility instead of using addition in the global utility function. By defining the utility of a violated hard constraint as 0, the global utility would also go to 0 if this hard constraint is not satisfied \cite{Chapman2011, Petcu2003}. A problem only containing hard constraints would represent a constraint satisfaction problem.

\[ u_{g}(s) = \prod_{\substack{hc_{k} \in HC}} u_{SC_{g}}(s) \bigg( \sum_{sc_{k} \in SC} u_{SC_{g}}(s) \bigg)\] 


% ----------------- Distributed Constraint Optimization --------------------
The definition of a distributed constraint problem extends the basic constraint optimization by distributing sets of variables to autonomous agents. These agents all have the goal to maximize the utility of their variables in a private utility function and thereby also contribute to a global utility function. Agents whose variables are linked to a common constraint are called neighbours \cite{Chapman2011, Farinelli, Petcu2003}.
\newline\newline 
% ----------------- Dynamic Distributed Constraint Optimization --------------------
As a further extension to the optimization, the problem definition is moved from a static to a dynamic attribute. Constraints can change and  therefore change neighbourhoods and the outcome of private and global utility functions. A change of constraints inherently changes the area of satisfying solutions if hard constraints have been included in a problem definition. Nguyen et al. state that changing the constraints might lead to the discovery of a better global optima.\cite{Nguyen2012}. Mailler et al. define a dynamic DCSP as a sequence of DCSPs \(\{P_{0}, P_{1}, ..., P_{n}\}\) where every DCSP is a static problem definition. \(P_{i}\) is therfore a result of the previous DSCP in the sequence and the added and removed constraints: \(P_{i} = P_{i-1} + c_{i^{a}} - c_{i^{r}}\) \cite{Maillera}. This definition should also hold for DCOPs. Utility functions could also be dynamically changed. Modifying this property could especially have an impact on real-world problems like meeting scheduling, where it could move the global optima from one disconnected solution space to another\cite{Nguyen2012}. Furthermore, variables could be added or removed in a dynamic setting and the problem domain \(D\) also could be changed during the course of the problem solving process.

\section{Meeting Scheduling Problem}  

%--------------------- Introduction with examples
Scheduling is the problem of allocating tasks to a given set of ressources that is usually limited with a time component. The meeting scheduling problem is a exemplary type of this family of problems and is supposedly well-know to all of us. Participants of a meeting have private schedules with preferences when a meeting should be held according to their calendar and the challenge is to identify a time for a meeting that maximizes the preferences of all participants while being valid in then sense that every person is able to attend \cite{Farinelli}. Angulo et al. have formally defined a meeting scheduling problem as:

\begin{itemize}
\item \(P = {p1, p, ... pn}\) is the set of people where every person has a calendar that hilds r slots, \(S = {s1,s2,s3}\)
\item \(M = {m1, m2, ..., m3}\) is a set of k meetings
\item \(At = {at1, at2, ..., atk}\) defines all attendee's of a meeting
\end{itemize}

The c parameter has been neglected as it is not relevant to this thesis \cite{angulo}. From the definition of a valid solution, one can derive two important criteria to the problem solving process:
\theoremstyle{definition}
\newtheorem{hardconstraint1}{Validity Criterium}
\begin{hardconstraint1}
All participants need to agree on the same time for the meeting.
\end{hardconstraint1}
\begin{hardconstraint1}
Meetings need to be scheduled in a way that there are no overlaps of meeting times in the schedules of the participants.
\end{hardconstraint1}
    
There is further an inherent privacy aspect to the problem. Meeting participant's are often not willing to share their schedules with others except for finding a time for the specific meeting. It will later be shown that some of the algorithms can guarantee this privacy to a certain degree. The meeting scheduling problem will be mapped as a distributed constraint optimization problem in the design chapter\cite{Farinelli, Angulo}.
    
    %--------------------- Explanation of the components with formal definition
   
    

\section{Algorithm Design Approaches}

\begin{figure}[h]
\includegraphics[width=400px]{graphics/overview_algos}
\caption{Categorization of DCO algorithms \cite{Chapman2011}}
\label{fig:categorization}
\end{figure}

Chapman et al. categorize distributed constraint optimization algorithms into local iterative and distributed complete algorithms. They further divide local iterative into message passing algorithms and approximate best response algorithms (Figure \ref{fig:categorization}). All of these approaches fullfill the anytime property, i.e they can provide a solution at every timepoint during calculation and all of them can be run synchronously as well as asynchronously with varying performances.
The following subsections are going to explain the differences between the three categories and introduce the concrete algorithms from these three different approaches that have been chosen for benchmarking. Advantages, as well as disadvantages will be described and which behaviour one can expect of these algorithms under certain parameters.

%Other Approaches: Bee Hive optimization, Genetic Algorithms, .. DynDCOAA, SBDO, Bee Colony algorithm, Ant colony algorithm, adopt, dsa-a, dsa-b stochastic ...\cite{Likhachev}
    
\subsection{Complete}

\cite{Chapman2011}

    %-----------------  Basic Concept and Advantages Disadvantes ----------------------

    
    
    %----------------- Structure ----------------------

\begin{figure}[H]
\centering
\includegraphics[width=250px]{graphics/pseudotree}
\caption{Pseudotree for DPOP \cite{Petcu2003}}
\label{fig:pseudotree}
\end{figure}

% ------------- Messages sent --------------------


%----------- Dynamics -----------------------


\subsection{Local-Iterative - Best Response}

%-----------------  Basic Concept and Advantages Disadvantes ----------------------

- neighbourhoods
- only communicates his state
- reacts to the states of others
- privacy aspects

\cite{Chapman2011}
\cite{Chapman2010}
\cite{Maheswaran} % Achtung muss das richtig paper finden

    - Local iterative approximate best-response algorithms, such as the distributed stochastic algorithm
(Tel, 2000; Fitzpatrick  Meertens, 2003), the maximum-gain messaging algorithm (Yokoo 
Hirayama, 1996; Maheswaran et al., 2005), fictitious play (Brown, 1951; Robinson, 1951),
adaptive play (Young, 1993, 1998), and regret matching (Hart  Mas-Colell, 2000). In this class,
agents exchange messages containing only their state, or can observe the strategies of their
neighbours. In game-theoretic parlance, this is known as standard monitoring2
, and, as the name
suggests, is a typical informational assumption implicit in the literature on learning in games.


    - advantages
    - disadvantages
    
    - mgm description
    
%----------------- Structure --------------------- 


% ------------- Messages sent --------------------


%----------- Dynamics -----------------------


\subsection{Local-Iterative - Message Passing}

%-----------------  Basic Concept and Advantages Disadvantes ----------------------
    
    \cite{Chapman2011} -> 
    
    - advantages
    -disadvantages: cycles, acyclic
    - privacy aspects
    - maxsum description

%----------------- Structure ----------------------

    \cite{Farinelli2008} -> fist paper

BIPARTITE GRAPH DEFINITION:

FACTOR GRAPH

\begin{figure}[H]
\centering
\includegraphics[width=170px]{graphics/factorgraph}
\caption{Conversion of a general DCOP to a factor graph\cite{Zivan2012}}
\label{fig:factorgraph}
\end{figure}

    
    Each node represent- ing a variable of the original DCOP is connected to all function- nodes that represent constraints that it is involved in. Similarly, a function-node is connected to all variable-nodes that represent variables in the original DCOP that are included in the constraint it represents. Agents

% ------------- Messages sent --------------------

From variable to function:
%Qn\→m(xn) = αnm \+ \?
%Rm\′\→n(xn)
%m\′\∈M(n)\m
%where αnm is a scaler chosen such that: (13)
%?
%Qn\→m(xn) = 0
%xn
From function to variable:
%(14)
%?
%?
%Rm\→n(xn) = maxxm\n
%?Um(xm)\+ ?
%Qn\′\→m(xn\′ )
%?
%n\′\∈\N(m)\n
%(15)

%It remains to describe the content of messages sent by the factor graph nodes. A message sent from a variable-node x to a function-
%node f at iteration i, includes for each of the values d ∈ Dx the sum of costs for this value it received from all function neighbors
%apart from f in iteration i − 1. Formally, for value d ∈ Dx the message will include

%A message sent from a function-node f to a variable-node x in
%iteration i includes for each possible value d ∈ Dx the minimal cost of any combination of assignments to the variables involved in f
%apart from x and the assignment of value d to variable x. Formally, the message from f to x includes for each value d ∈ Dx:

%----------- Dynamics -----------------------
Finally, we note that if messages are continuously propagated,
and the states of the agents are continuously updated, then the algo- rithm may be applied to dynamic problems where the interactions between agents, or the utilities resulting from these interactions, may change at any time. For example, within tracking problems where the decentralised coordination algorithm is being used to fo- cus different sensors onto different targets (as described in [15]), then the utilities of each sensor are continually changing due to the changing position of targets, and the actions of other sensors. Thus, by continually propagatingmessages each agent is able tomaintain a continuously updated estimate of the state that it should adopt in order to maximise social welfare in this dynamic problem4. Farinelli
    
    